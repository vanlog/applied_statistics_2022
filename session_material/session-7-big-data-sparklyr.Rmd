---
title: "Big data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Reference

- [Mastering Spark with R](https://therinspark.com/) *Javier Luraschi, Kevin Kuo, Edgar Ruiz*
- [SparkR](https://spark.apache.org/docs/latest/sparkr.html)


## Map Reduce

```{r}
library(purrr)

n <- 10^5

rnd_couple <- function(x) {
  list(x = runif(1, min = -1, max = 1),
       y = runif(1, min = -1, max = 1))
}


points <- map(seq_len(n), rnd_couple)
```


```{r}
# function ----------------------------------------------------------------

in_circle <- function(point) {
  point$x^2 + point$y^2 < 1
}

counter_to_pi <- function(count, total) {
  count/total * 4
}
```


```{r}
# first for-loop ----------------------------------------------------------

counter <- 0
for (point_idx in seq_along(points)) {
  point <- points[[point_idx]]
  counter <- counter + in_circle(point)
}
counter_to_pi(counter, n)

# split -------------------------------------------------------------------
```


```{r}
## ideally a map or lapply
are_points_in_circle <- numeric(n)
for (point_idx in seq_along(points)) {
  point <- points[[point_idx]]
  are_points_in_circle[[point_idx]] <- in_circle(point)
}

## ideally a reduce
counter <- 0
for (is_point_in_circle in are_points_in_circle) {
  counter <- counter + is_point_in_circle
}
counter_to_pi(counter, n)
```


```{r}
# lapply ------------------------------------------------------------------

are_points_in_circle <- map(points, in_circle)
counter <- reduce(are_points_in_circle, `+`)
counter_to_pi(counter, n)


map(points, in_circle) %>%
  reduce(`+`) %>%
  counter_to_pi( n)
```

